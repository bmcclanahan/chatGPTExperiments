{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "396d66db-27bc-448b-a372-e93c73ad2eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (0.0.221)\n",
      "Requirement already satisfied: tiktoken in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (0.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from langchain) (2.0.17)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from langchain) (0.5.9)\n",
      "Requirement already satisfied: langchainplus-sdk>=0.0.17 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from langchain) (0.0.19)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from langchain) (1.10.8)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from tiktoken) (2023.6.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from pydantic<2,>=1->langchain) (4.6.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/brianmcclanahan/opt/anaconda3/envs/py39/lib/python3.9/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "964f7b47-732f-476a-8b2b-1b1f471a9249",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/state_of_the_union/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2002968d-cf0b-4350-9d98-9e4f8806c6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "paths = [os.path.join(data_dir, f) for f in os.listdir(data_dir)]\n",
    "texts = [open(path, 'r').read().replace('\\n\\n', '\\n') for path in paths if path.endswith('.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf0888a8-e443-44b3-9563-caaa6bb97b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44ee6f38-d941-430c-b58e-1be9a0c06137",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(separator = \".\", chunk_size=3000, chunk_overlap=100)\n",
    "docs = text_splitter.create_documents([texts[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6007af72-eed5-4a6c-9c62-2b395fb0bc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.base import BasePromptTemplate\n",
    "from langchain import LLMChain, OpenAI, PromptTemplate\n",
    "from langchain.text_splitter import TextSplitter\n",
    "from typing import Any, Dict, Optional, List\n",
    "from langchain.callbacks.manager import CallbackManagerForChainRun\n",
    "from langchain.chains.summarize import load_summarize_chain, refine_prompts\n",
    "from langchain.schema import LLMResult, Generation\n",
    "\n",
    "\n",
    "class RefineLLMChain(LLMChain):\n",
    "    \"\"\"Chain to run queries against LLMs. Queries can be large and will be broken up and\n",
    "    processed incrementally using the Refine summarize strategy. Only one input key allowed.\n",
    "\n",
    "    Example:\n",
    "        .. code-block:: python\n",
    "\n",
    "            from langchain import LLMChain, OpenAI, PromptTemplate\n",
    "            prompt_template = \"Tell me a {adjective} joke\"\n",
    "            prompt = PromptTemplate(\n",
    "                input_variables=[\"adjective\"], template=prompt_template\n",
    "            )\n",
    "            llm = LLMChain(llm=OpenAI(), prompt=prompt)\n",
    "    \"\"\"\n",
    "    \n",
    "    text_splitter: TextSplitter\n",
    "    \"\"\"TextSplitter used to split up the input text if necessary (e.g. input text is too long to use for a single call\n",
    "    to LLM)\n",
    "    \"\"\"\n",
    "    question_prompt: BasePromptTemplate = refine_prompts.PROMPT\n",
    "    \"\"\"Question prompt for refine chain\n",
    "    \"\"\"\n",
    "    refine_prompt: BasePromptTemplate = refine_prompts.REFINE_PROMPT\n",
    "    \"\"\"Refine prompt for refine chain\n",
    "    \"\"\"\n",
    "\n",
    "    # def _call(\n",
    "    #     self,\n",
    "    #     inputs: Dict[str, Any],\n",
    "    #     run_manager: Optional[CallbackManagerForChainRun] = None,\n",
    "    # ) -> Dict[str, str]:\n",
    "    #     text = inputs[self.prompt.input_variables[0]] # do some input validation here. checking that there is only one key in the dict\n",
    "    #     docs = self.text_splitter.create_documents([text])\n",
    "    #     with open(\"doc_nums.txt\", \"a\") as myfile:\n",
    "    #         myfile.write(f\"appended text {len(docs)}\")\n",
    "    #     refine_chain = load_summarize_chain(self.llm, chain_type=\"refine\")\n",
    "    #     output = refine_chain({\"input_documents\": docs}, return_only_outputs=True)\n",
    "    #     return {'text': output['output_text']}\n",
    "\n",
    "\n",
    "    def generate( # this is a hack and should be refactored\n",
    "        self,\n",
    "        input_list: List[Dict[str, Any]],\n",
    "        run_manager: Optional[CallbackManagerForChainRun] = None,\n",
    "    ) -> LLMResult:\n",
    "        \"\"\"Generate LLM result from inputs.\"\"\"\n",
    "        # prompts, stop = self.prep_prompts(input_list, run_manager=run_manager)\n",
    "        # output = self.llm.generate_prompt(\n",
    "        #     prompts,\n",
    "        #     stop,\n",
    "        #     callbacks=run_manager.get_child() if run_manager else None,\n",
    "        #     **self.llm_kwargs,\n",
    "        # )\n",
    "        refine_chain = load_summarize_chain(\n",
    "            self.llm, chain_type=\"refine\",\n",
    "            refine_prompt=self.refine_prompt,\n",
    "            question_prompt=self.question_prompt, \n",
    "        )\n",
    "        generations = []\n",
    "        for index, input_item in enumerate(input_list):\n",
    "            print(\"processing\", index)\n",
    "            text = input_item[self.prompt.input_variables[0]] # do some input validation here. checking that there is only one key in the dict\n",
    "            docs = self.text_splitter.create_documents([text])\n",
    "            output = refine_chain(\n",
    "                {\"input_documents\": docs}, return_only_outputs=True\n",
    "            )\n",
    "            generations.append([Generation(text=output[\"output_text\"])])\n",
    "        return LLMResult(generations=generations)\n",
    "    \n",
    "    \"\"\"\n",
    "    todo: implement async call\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1e029d1-80f5-4f8f-927e-28782bfda183",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm1 = OpenAI()\n",
    "llm2 = OpenAI() # can probably just use one variable here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d730d806-1f4e-4be4-9f3b-a72a1bf891c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_text_splitter = CharacterTextSplitter(separator = \".\", chunk_size=1000, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cf809dc-8d50-4ffa-b06c-e9cadcb3d6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"{text}\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"], template=prompt_template\n",
    ") # kinda hacky but works\n",
    "refineLLMChain = RefineLLMChain(llm=llm1, prompt=prompt, text_splitter=refine_text_splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ef0ec8-f851-40b0-9c42-3078b380eaf8",
   "metadata": {},
   "source": [
    "Test the output of the custom RefineLLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a982ffa3-6248-47a7-baa4-6c816379baa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': \"\\n\\nIn just three years, America has made a great comeback with a booming economy, soaring incomes, plummeting poverty, falling crime, and increased confidence. The country is also gaining respect on the world stage and is no longer used, taken advantage of, or scorned by other nations. Through reversing the failed economic policies of the previous administration, enacting historic and record-setting tax cuts, and fighting for fair and reciprocal trade agreements, 7 million new jobs have been created and the unemployment rate has reached the lowest levels in history for African Americans, Hispanic Americans, and Asian Americans. Our military is completely rebuilt, with its power being unmatched anywhere in the world, our borders are secure, our families are flourishing, our values are renewed, and our pride is restored. We have the opportunity to build the world's most prosperous and inclusive society, where every citizen can join in America's success and every community can take part in America's rise.\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refineLLMChain({\"text\": docs[0].page_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1931de4d-c1f2-4e27-9643-f3b8dc393540",
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_chain = load_summarize_chain(llm2, chain_type=\"refine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e103f124-afae-4f77-aa64-308ac14de58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain\n",
    "\n",
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    llm_chain=refineLLMChain,\n",
    "    combine_document_chain=refine_chain,\n",
    "    return_intermediate_steps=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60c6321-c142-4ae5-b94f-a0c57fa6babb",
   "metadata": {},
   "source": [
    "Test the custom MapReduceDocumentChain that uses a refine summarizing strategy for both the map and reduce steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb05046-7f8f-425a-967d-cace6de417a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 0\n",
      "processing 1\n",
      "processing 2\n"
     ]
    }
   ],
   "source": [
    "output = map_reduce_chain({\"input_documents\": docs[:3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4a5881-bc51-4289-be5c-7fe6d8099700",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b89baf-e37e-4e88-91d6-ad2f118afe1f",
   "metadata": {},
   "source": [
    "### Now we will use a custom MapReduceDocumentsChain to summarize and contrast the State of the Union speeches of President Obama, Trump, and Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e102c32-cba4-434c-a1b4-9d0f9563a345",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Write a concise summary of the following:\n",
    "\n",
    "{text}\n",
    "\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "refine_template = (\n",
    "    \"Your job is to produce a final summary constrasting the state of the union speeches of President Biden, Trump, and Obama.\\n\"\n",
    "    \"We have provided an existing summary up to a certain point: {existing_answer}\\n\"\n",
    "    \"We have the opportunity to refine the existing summary\"\n",
    "    \"(only if needed) with some more context below.\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"{text}\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"Given the new context, refine the original summary.\"\n",
    "    \"If the context isn't useful, return the original summary.\"\n",
    ")\n",
    "refine_prompt = PromptTemplate(\n",
    "    input_variables=[\"existing_answer\", \"text\"],\n",
    "    template=refine_template,\n",
    ")\n",
    "\n",
    "refine_chain = load_summarize_chain(llm2, chain_type=\"refine\", question_prompt=PROMPT, refine_prompt=refine_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b245326f-c7f6-49f9-9fe0-7a4d9ad0e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_text_splitter = CharacterTextSplitter(separator = \".\", chunk_size=3000, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf053c2-eeb2-4c78-aa2e-7ff7b0a7e4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"{text}\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"], template=prompt_template\n",
    ") # kinda hacky but works\n",
    "refineLLMChain = RefineLLMChain(llm=llm1, prompt=prompt, text_splitter=refine_text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497ed997-4f17-4682-9ec5-353cbc4d367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain\n",
    "\n",
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    llm_chain=refineLLMChain,\n",
    "    combine_document_chain=refine_chain,\n",
    "    return_intermediate_steps=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd9dad1-e672-42bc-bf65-dbabc8113bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "president_names = [ path.split('/')[-1].replace('.txt', '') for path in paths if path.endswith('.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b4a40a-9bd9-4f5a-90a6-b26b2bd28235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "docs = [Document(page_content=f\"President {president_names[index]}:\\n{text}\") for index, text in enumerate(texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396e5adc-0bbe-4e24-b64b-1b7cc838b99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = map_reduce_chain({\"input_documents\": docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b00c3c-9596-4a5d-a056-74b5f65992b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['intermediate_steps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2fda3e-34f4-4beb-a607-407d42fa8401",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['output_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0c27f9-b16f-4103-b983-38d688bd0a08",
   "metadata": {},
   "source": [
    "Looks like the output was cut short for some reason. Lets try using a StuffChain for the combine chain of the MapReduceChain. The MapReduceChain is recursive if necessary, breaking a longer list of documents (after the initial map step) up into multiple shorter lists that can be processed without LLM context window issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485593fc-3ff6-4272-91a1-d6cefe789816",
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff_chain = load_summarize_chain(llm2, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88168c5-ca97-43b6-8b39-734ebf992878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain\n",
    "\n",
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    llm_chain=refineLLMChain,\n",
    "    combine_document_chain=stuff_chain,\n",
    "    return_intermediate_steps=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9531f5b-b463-4201-93fa-28aeae3d5105",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = map_reduce_chain({\"input_documents\": docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb203d37-6e0e-4b86-977c-74ea9ff40852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
